---
title: "Michelson Speed-of-light Measurements"
author: "(Khor Zhi Hong)"
date: 2025-Feb-12
output: 
  github_document:
    toc: true
prerequisites:
  - e-data02-derive
---

*Purpose*: When studying physical problems, there is an important distinction between *error* and *uncertainty*. The primary purpose of this challenge is to dip our toes into these factors by analyzing a real dataset.

*Reading*: [Experimental Determination of the Velocity of Light](https://play.google.com/books/reader?id=343nAAAAMAAJ&hl=en&pg=GBS.PA115) (Optional)

<!-- include-rubric -->
# Grading Rubric
<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics define how you will be graded, both on an individual and team basis.

## Individual
<!-- ------------------------- -->

| Category | Needs Improvement | Satisfactory |
|----------|----------------|--------------|
| Effort | Some task __q__'s left unattempted | All task __q__'s attempted |
| Observed | Did not document observations, or observations incorrect | Documented correct observations based on analysis |
| Supported | Some observations not clearly supported by analysis | All observations clearly supported by analysis (table, graph, etc.) |
| Assessed | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support |
| Specified | Uses the phrase "more data are necessary" without clarification | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability | Code sufficiently close to the [style guide](https://style.tidyverse.org/) |

## Submission
<!-- ------------------------- -->

Make sure to commit both the challenge report (`report.md` file) and supporting files (`report_files/` folder) when you are done! Then submit a link to Canvas. **Your Challenge submission is not complete without all files uploaded to GitHub.**


```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(googlesheets4)

url <- "https://docs.google.com/spreadsheets/d/1av_SXn4j0-4Rk0mQFik3LLr-uf0YdA06i3ugE6n-Zdo/edit?usp=sharing"

# Parameters
LIGHTSPEED_VACUUM    <- 299792.458 # Exact speed of light in a vacuum (km / s)
LIGHTSPEED_MICHELSON <- 299944.00  # Michelson's speed estimate (km / s)
LIGHTSPEED_PM        <- 51         # Michelson error estimate (km / s)
```

*Background*: In 1879 Albert Michelson led an experimental campaign to measure the speed of light. His approach was a development upon the method of Foucault[3], and resulted in a new estimate of $v_0 = 299944 \pm 51$ kilometers per second (in a vacuum). This is very close to the modern *exact* value of `r LIGHTSPEED_VACUUM`. In this challenge, you will analyze Michelson's original data, and explore some of the factors associated with his experiment.

I've already copied Michelson's data from his 1880 publication; the code chunk below will load these data from a public googlesheet.

*Aside*: The speed of light is *exact* (there is **zero error** in the value `LIGHTSPEED_VACUUM`) because the meter is actually [*defined*](https://en.wikipedia.org/wiki/Metre#Speed_of_light_definition) in terms of the speed of light!

```{r read-sheet}
## Note: No need to edit this chunk!
gs4_deauth()
ss <- gs4_get(url)
df_michelson <-
  read_sheet(ss) %>%
  select(Date, Distinctness, Temp, Velocity) %>%
  mutate(Distinctness = as_factor(Distinctness))

df_michelson %>% glimpse()
```

*Data dictionary*:

- `Date`: Date of measurement
- `Distinctness`: Distinctness of measured images: 3 = good, 2 = fair, 1 = poor
- `Temp`: Ambient temperature (Fahrenheit)
- `Velocity`: Measured speed of light (km / s)

### __q1__ Re-create the following table (from Michelson (1880), pg. 139) using `df_michelson` and `dplyr`. Note that your values *will not* match those of Michelson *exactly*; why might this be?

| Distinctness | n  | MeanVelocity |
|--------------|----|----------|
|            3 | 46 |   299860 |
|            2 | 39 |   299860 |
|            1 | 15 |   299810 |

```{r q1-task}
## TODO: Compute summaries
df_q1 <- df_michelson %>%
  group_by(Distinctness) %>%
  summarise(
    n=n(),
    MeanVelocity = round(mean(Velocity))
  )
df_q1 %>%
  arrange(desc(Distinctness)) %>%
  knitr::kable()
```

**Observations**:
- Write your observations here!
  - they have the same value distinctness and n while their MeanVelocity have a difference of 2 each.
- Why might your table differ from Michelson's?
  - the dataset used for the MeanVelocity is different
  -the measuring tools used may have resulted in the different data set collected 
  -the data processing method may be different, which some dataset may have been excluded or correct resulting difference in dataset
  -The mean velocity may have been rounded off differently resulting in slight differences of 2.

The `Velocity` values in the dataset are the speed of light *in air*; Michelson
introduced a couple of adjustments to estimate the speed of light in a vacuum.
In total, he added $+92$ km/s to his mean estimate for `VelocityVacuum` (from
Michelson (1880), pg. 141). While the following isn't fully rigorous ($+92$ km/s
is based on the mean temperature), we'll simply apply this correction to all the
observations in the dataset.

### __q2__ Create a new variable `VelocityVacuum` with the $+92$ km/s adjustment to `Velocity`. Assign this new dataframe to `df_q2`.

```{r q2-task}
## TODO: Adjust the data, assign to df_q2
df_q2 <- df_michelson %>%
  mutate(VelocityVacuum = Velocity +92)

df_q2
```

As part of his study, Michelson assessed the various potential sources of error,
and provided his best-guess for the error in his speed-of-light estimate. These
values are provided in `LIGHTSPEED_MICHELSON`---his nominal estimate---and
`LIGHTSPEED_PM`---plus/minus bounds on his estimate. Put differently, Michelson
believed the true value of the speed-of-light probably lay between
`LIGHTSPEED_MICHELSON - LIGHTSPEED_PM` and `LIGHTSPEED_MICHELSON +
LIGHTSPEED_PM`.

Let's introduce some terminology:[2]

- **Error** is the difference between a true value and an estimate of that
  value; for instance `LIGHTSPEED_VACUUM - LIGHTSPEED_MICHELSON`.
- **Uncertainty** is an analyst's *assessment* of the error.

Since a "true" value is often not known in practice, one generally does not know
the error. The best they can do is quantify their degree of uncertainty. We will
learn some means of quantifying uncertainty in this class, but for many real
problems uncertainty includes some amount of human judgment.[2]

### __q3__ Compare Michelson's speed of light estimate against the modern speed of light value. Is Michelson's estimate of the error (his uncertainty) greater or less than the true error?

```{r q3-task}
## TODO: Compare Michelson's estimate and error against the true value
## Your code here!
MordenLightspeed<- 299792.458
uncertainty_michelson<- LIGHTSPEED_PM
error_michelson<- MordenLightspeed - LIGHTSPEED_MICHELSON

Mestimate<- ifelse(abs(error_michelson) > uncertainty_michelson,"Underestimate",
                ifelse(abs(error_michelson) < uncertainty_michelson, "Overestimate",
                "Accurate"))

data.frame(
  LIGHTSPEED_MICHELSON=LIGHTSPEED_MICHELSON,
  MordenLightspeed= MordenLightspeed,
  uncertainty_michelson= uncertainty_michelson,
  True_error=error_michelson,
  Over_or_Under_estimate=Mestimate
)
```

**Observations**:
- Is Michelson's estimate of the error (his uncertainty) greater or less than the true error?
  - His estimate of error is lesser than his true error
- Make a quantitative comparison between Michelson's uncertainty and his error.
  - he under estimated his uncertainty, where his true error value(absolute value) is larger than the uncertainty made.
  -the Michelson light speed is 151.542 lower than the modern light speed, this negative True error.

The following plot shows all of Michelson's data as a [control chart](https://en.wikipedia.org/wiki/Control_chart); this sort of plot is common in manufacturing, where it is used to help determine if a manufacturing process is under [statistical control](https://en.wikipedia.org/wiki/Statistical_process_control). Each dot is one of Michelson's measurements, and the grey line connects the mean taken for each day. The same plot also shows simulated data using a probability model. We'll get into statistics later in the course; for now, let's focus on understanding what real and simulated data tend to look like.

### __q4__ Inspect the following plot with the `Real` Michelson data and `Simulated` data from a probability model. Document the similarities and differences between the data under *observe* below.

```{r q4-cf-real-simulated}
## Note: No need to edit this chunk!
## Calibrate simulated data
v_mean <-
  df_q2 %>%
  summarize(m = mean(VelocityVacuum)) %>%
  pull(m)
v_sd <-
  df_q2 %>%
  summarize(s = sd(VelocityVacuum)) %>%
  pull(s)

## Visualize
set.seed(101)
df_q2 %>%
  mutate(Simulated = rnorm(n(), mean = v_mean, sd = v_sd)) %>%
  rename(Real = VelocityVacuum) %>%
  pivot_longer(
    cols = c(Simulated, Real),
    names_to = "source",
    values_to = "velocity"
  ) %>%

  ggplot(aes(Date, velocity)) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON,
    linetype = "dotted"
  ) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON - LIGHTSPEED_PM,
    linetype = "dashed"
  ) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON + LIGHTSPEED_PM,
    linetype = "dashed"
  ) +

  geom_line(
    data = . %>%
      group_by(Date, source) %>%
      summarize(velocity_mean = mean(velocity)),
    mapping = aes(y = velocity_mean),
    color = "grey50"
  ) +
  geom_point(
    mapping = aes(y = velocity),
    size = 0.8
  ) +

  facet_grid(source~.) +
  theme_minimal() +
  labs(
    x = "Date of Measurement (1879)",
    y = "Velocity (in Vacuum)"
  )
```

**Observations**:
Similarities
- both display similar trend and pattern in velocity against time.
-both have similar mean velocity in the middle 300000 and 299900
- judging the data with normal distribution, the standard deviation seems to look similar where the overall variance around the mean is similar
Differences
- the outliers value in the real data seems to be larger than the outlier values of the simulated data 
-between jun 09 to jun 23, the real data seems to be more clustered than the simulated data, where simulated data seems to have the data points more spaced apart
-The real data seems to show greater fluctuations than compared to simulated data within jun 02 to jun 16, while stimulated data seems to show slightly greater fluctuation than real data from jun 23 to jun 30

### __q5__ You have access to a few other variables. Construct a **at least three** visualizations of `VelocityVacuum` against these other factors. Are there other patterns in the data that might help explain the difference between Michelson's estimate and `LIGHTSPEED_VACUUM`?
```{r}
# i assume we use the VelocityVacuum in df_q2 and put it over Q4
## Calibrate simulated data
v_mean <-
  df_q2 %>%
  summarize(m = mean(VelocityVacuum)) %>%
  pull(m)
v_sd <-
  df_q2 %>%
  summarize(s = sd(VelocityVacuum)) %>%
  pull(s)

## Visualize
set.seed(101)
df_q2 %>%
  mutate(Simulated = rnorm(n(), mean = v_mean, sd = v_sd)) %>%
  rename(Real = VelocityVacuum) %>%
  pivot_longer(
    cols = c(Simulated, Real),
    names_to = "source",
    values_to = "velocity"
  ) %>%

  ggplot(aes(Distinctness, velocity)) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON,
    linetype = "dotted"
  ) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON - LIGHTSPEED_PM,
    linetype = "dashed"
  ) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON + LIGHTSPEED_PM,
    linetype = "dashed"
  ) +

  geom_line(
    data = . %>%
      group_by(Distinctness, source) %>%
      summarize(velocity_mean = mean(velocity)),
    mapping = aes(y = velocity_mean),
    color = "grey50"
  ) +
  geom_point(
    mapping = aes(y = velocity),
    size = 0.8
  ) +

  facet_grid(source~.) +
  theme_minimal() +
  labs(
    x = "Date of Measurement (1879)",
    y = "Velocity (in Vacuum)"
  )
```


**Observations**:

- Make sure to record observations on your graphs!

While plotting Velocity against time
-the outliers seems to bring about greater fluctuations to the graph
-the plots are for spaced apart 
-the outliers and the fluctuations may explain why there is discrepancies in Michelson's estimate
-there seems to be a weaker correlations between temperature and velocity than date and velocity


while plotting velocity against Distinctness of image
- the poor images (1) seems to be more spaced apart compared to 2 and 3, which seems to introduce more variability
-the good images (3) seems to be more clustered and higher velocity than (2) and (3)
-the errors may be related to the distinctness of image, the poorer the distinctness of image the increase of error 



while plotting velocity against date
- there seems to be a larger deviations from the mean and also variance than when plotting against temperature, 
- there is a greater fluctuations than temperature, and there maybe impact of temperature on the fluctuation of velocity against time.


## Bibliography

- [1] Michelson, [Experimental Determination of the Velocity of Light](https://play.google.com/books/reader?id=343nAAAAMAAJ&hl=en&pg=GBS.PA115) (1880)
- [2] Henrion and Fischhoff, [Assessing Uncertainty in Physical Constants](https://www.cmu.edu/epp/people/faculty/research/Fischoff-Henrion-Assessing%20uncertainty%20in%20physical%20constants.pdf) (1986)
- [3] BYU video about a [Fizeau-Foucault apparatus](https://www.youtube.com/watch?v=Ik5ORaaeaME), similar to what Michelson used.
